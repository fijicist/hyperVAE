# ═══════════════════════════════════════════════════════════════════════════
# HYPERVAE REQUIREMENTS - MEMORY-OPTIMIZED JET GENERATION WITH L-GATr
# ═══════════════════════════════════════════════════════════════════════════
#
# Installation Instructions:
# --------------------------
# 1. Create virtual environment:
#    python -m venv venv
#    source venv/bin/activate  # Linux/Mac
#    # OR: venv\Scripts\activate  # Windows
#
# 2. Install PyTorch with CUDA (if using GPU):
#    # For CUDA 12.1 (GTX 1650 Ti compatible):
#    pip install torch==2.2.0 torchvision==0.18.1 --index-url https://download.pytorch.org/whl/cu121
#    
#    # For CUDA 11.8:
#    pip install torch==2.2.0 torchvision==0.18.1 --index-url https://download.pytorch.org/whl/cu118
#    
#    # For CPU only:
#    pip install torch==2.2.0 torchvision==0.18.1
#
# 3. Install PyTorch Geometric and dependencies:
#    pip install torch-geometric
#    pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html
#
# 4. Install remaining requirements:
#    pip install -r requirements.txt
#
# Tested Configuration:
# ---------------------
# - Python: 3.10+
# - PyTorch: 2.2.0+cu121
# - CUDA: 12.1
# - GPU: GTX 1650 Ti (4GB VRAM)
# - OS: Linux (Ubuntu 22.04), compatible with Windows/Mac
#
# ═══════════════════════════════════════════════════════════════════════════

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ CORE DEEP LEARNING FRAMEWORK                                             │
# └─────────────────────────────────────────────────────────────────────────┘
# PyTorch: Main deep learning framework
# Note: Install separately with CUDA support (see instructions above)
torch>=2.2.0
torchvision>=0.18.0

# PyTorch Geometric: Graph neural network library for jet representation
torch-geometric>=2.6.0

# PyG Sparse Operations: Required for efficient graph operations
# Note: Install via PyG wheel (see instructions above) or:
torch-scatter>=2.1.0
torch-sparse>=0.6.16
torch-cluster>=1.6.0
torch-spline-conv>=1.2.0
pyg-lib>=0.4.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ L-GATr: LORENTZ-EQUIVARIANT TRANSFORMER (KEY INNOVATION)                │
# └─────────────────────────────────────────────────────────────────────────┘
# Official L-GATr library for Lorentz-equivariant neural networks
lgatr>=1.3.0

# Geometric Algebra Transformer (base architecture for L-GATr)
# gatr is automatically installed as lgatr dependency, but listed for clarity
# gatr>=1.0.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ SCIENTIFIC COMPUTING & NUMERICS                                          │
# └─────────────────────────────────────────────────────────────────────────┘
# NumPy: Array operations and numerical computing
numpy>=1.26.0

# SciPy: Statistical functions (wasserstein_distance for evaluation)
scipy>=1.14.0

# Numba: JIT compilation for fast numerical functions (used in utils.py)
numba>=0.58.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ PARTICLE PHYSICS LIBRARIES                                               │
# └─────────────────────────────────────────────────────────────────────────┘
# FastJet: Jet clustering and analysis (for graph_constructor.py)
fastjet>=3.4.0

# Awkward Array: Ragged/nested array operations for particle physics
awkward>=2.6.0

# EnergyFlow: Particle physics datasets and observables
energyflow>=1.3.0

# EnergyEnergyCorrelators: Compute energy correlators for jets (utils.py)
# Note: This is 'eec' in the code, installed as EnergyEnergyCorrelators
energyenergycorrelators>=2.0.0b1

# JetNet: Standard jet datasets (graph_constructor.py)
jetnet>=0.2.5

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ MACHINE LEARNING UTILITIES                                               │
# └─────────────────────────────────────────────────────────────────────────┘
# Scikit-learn: Preprocessing utilities (OneHotEncoder, StandardScaler)
scikit-learn>=1.5.0

# Joblib: Parallel processing for data loading
joblib>=1.4.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ VISUALIZATION & PLOTTING                                                 │
# └─────────────────────────────────────────────────────────────────────────┘
# Matplotlib: Plotting and visualization
matplotlib>=3.9.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ LOGGING & MONITORING                                                     │
# └─────────────────────────────────────────────────────────────────────────┘
# TensorBoard: Training visualization and logging
tensorboard>=2.18.0

# tqdm: Progress bars
tqdm>=4.66.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ CONFIGURATION & I/O                                                      │
# └─────────────────────────────────────────────────────────────────────────┘
# PyYAML: Configuration file parsing
pyyaml>=6.0

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ GRAPH UTILITIES                                                          │
# └─────────────────────────────────────────────────────────────────────────┘
# NetworkX: Graph algorithms and visualization (graph_constructor.py)
networkx>=3.3

# ┌─────────────────────────────────────────────────────────────────────────┐
# │ OPTIONAL DEPENDENCIES                                                    │
# └─────────────────────────────────────────────────────────────────────────┘
# These are used for specific tasks and can be omitted if not needed

# h5py: HDF5 file support (if using HDF5 datasets)
# h5py>=3.11.0

# Wasserstein: Alternative Wasserstein distance implementation
# wasserstein>=1.1.0  # Already available via scipy.stats

# ═══════════════════════════════════════════════════════════════════════════
# DEVELOPMENT DEPENDENCIES (Optional)
# ═══════════════════════════════════════════════════════════════════════════
# Uncomment if doing development work:

# pytest: Testing framework
# pytest>=8.3.0

# black: Code formatter
# black>=24.0.0

# flake8: Linting
# flake8>=7.0.0

# ═══════════════════════════════════════════════════════════════════════════
# TROUBLESHOOTING
# ═══════════════════════════════════════════════════════════════════════════
#
# Issue: torch-geometric installation fails
# Solution: Install PyTorch first, then use PyG wheel matching your PyTorch/CUDA:
#   pip install torch-geometric
#   pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu121.html
#
# Issue: lgatr import error
# Solution: Ensure you have compatible PyTorch (>=2.0) and install lgatr:
#   pip install lgatr
#
# Issue: fastjet not found
# Solution: Install fastjet via pip (may require compiler):
#   pip install fastjet
#   # If compilation fails, try: conda install -c conda-forge fastjet
#
# Issue: CUDA out of memory during training
# Solution: Reduce batch_size in config.yaml or increase gradient_accumulation_steps
#
# Issue: Numba compilation errors
# Solution: Update numba to latest version:
#   pip install --upgrade numba
#
# ═══════════════════════════════════════════════════════════════════════════
